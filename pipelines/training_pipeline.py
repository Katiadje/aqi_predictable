import os
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import xgboost as xgb
import joblib
import hopsworks
from hsml.model_registry import ModelRegistry
import warnings
import sys
import argparse
from datetime import datetime
warnings.filterwarnings('ignore')

class AQITrainingPipeline:
    def __init__(self):
        self.models = {}
        self.scaler = StandardScaler()
        self.feature_importance = {}
        
    def connect_to_hopsworks(self):
        """Se connecte √† Hopsworks"""
        try:
            project = hopsworks.login(
                api_key_value=os.getenv('HOPSWORKS_API_KEY'),
                project="aqi_prediction"
            )
            return project.get_feature_store(), project.get_model_registry()
        except Exception as e:
            print(f"‚ùå Erreur de connexion √† Hopsworks: {e}")
            return None, None
    
    def load_training_data(self, fs):
        """Charge les donn√©es d'entra√Ænement depuis le feature store"""
        try:
            # R√©cup√©ration du feature group
            aqi_fg = fs.get_feature_group(name="aqi_features", version=1)
            
            # Cr√©ation d'une requ√™te pour r√©cup√©rer les donn√©es
            query = aqi_fg.select_all()
            df = query.read()
            
            print(f"üìä Donn√©es charg√©es: {len(df)} enregistrements")
            return df
            
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur lors du chargement des donn√©es: {e}")
            print("üîÑ G√©n√©ration de donn√©es simul√©es pour la d√©mo...")
            
            # G√©n√©ration de donn√©es simul√©es si Hopsworks n'est pas disponible
            dates = pd.date_range(end=datetime.now(), periods=500, freq='H')
            
            np.random.seed(42)  # Pour la reproductibilit√©
            base_aqi = np.random.normal(80, 30, 500)
            base_aqi = np.clip(base_aqi, 10, 300)
            
            df = pd.DataFrame({
                'timestamp': dates,
                'city': ['barcelona'] * 500,
                'aqi': base_aqi,
                'pm25': base_aqi * 0.6 + np.random.normal(0, 10, 500),
                'pm10': base_aqi * 0.8 + np.random.normal(0, 15, 500),
                'o3': base_aqi * 0.4 + np.random.normal(0, 8, 500),
                'no2': base_aqi * 0.3 + np.random.normal(0, 5, 500),
                'so2': base_aqi * 0.2 + np.random.normal(0, 3, 500),
                'co': base_aqi * 0.1 + np.random.normal(0, 2, 500),
                'temp': np.random.normal(20, 5, 500),
                'humidity': np.random.normal(60, 15, 500),
                'pressure': np.random.normal(1013, 10, 500),
                'wind_speed': np.random.uniform(0, 10, 500),
                'hour': [d.hour for d in dates],
                'day_of_week': [d.dayofweek for d in dates],
                'month': [d.month for d in dates],
                'is_weekend': [d.dayofweek >= 5 for d in dates],
                'season': [self._get_season(d.month) for d in dates]
            })
            
            # Calcul des features d√©riv√©es
            df['pm_ratio'] = df['pm25'] / np.maximum(df['pm10'], 1)
            df['pollution_score'] = (df['pm25'] * 0.4 + df['pm10'] * 0.3 + 
                                   df['o3'] * 0.2 + df['no2'] * 0.1)
            df['temp_humidity_index'] = df['temp'] * df['humidity'] / 100
            df['air_quality_category'] = df['aqi'].apply(self._categorize_aqi)
            
            # Nettoyage des valeurs n√©gatives
            numeric_cols = ['pm25', 'pm10', 'o3', 'no2', 'so2', 'co']
            for col in numeric_cols:
                df[col] = np.maximum(df[col], 0)
            
            print(f"‚úÖ Donn√©es simul√©es g√©n√©r√©es: {len(df)} enregistrements")
            return df
    
    def _get_season(self, month):
        """D√©termine la saison bas√©e sur le mois"""
        if month in [12, 1, 2]:
            return 0  # Hiver
        elif month in [3, 4, 5]:
            return 1  # Printemps
        elif month in [6, 7, 8]:
            return 2  # √ât√©
        else:
            return 3  # Automne
    
    def _categorize_aqi(self, aqi):
        """Cat√©gorise l'AQI selon les standards internationaux"""
        if aqi <= 50:
            return 0  # Bon
        elif aqi <= 100:
            return 1  # Mod√©r√©
        elif aqi <= 150:
            return 2  # Malsain pour groupes sensibles
        elif aqi <= 200:
            return 3  # Malsain
        elif aqi <= 300:
            return 4  # Tr√®s malsain
        else:
            return 5  # Dangereux
    
    def prepare_features(self, df):
        """Pr√©pare les features pour l'entra√Ænement"""
        if df.empty:
            return None, None, None, None
        
        # S√©lection des features pour l'entra√Ænement
        feature_cols = [
            'pm25', 'pm10', 'o3', 'no2', 'so2', 'co',
            'temp', 'humidity', 'pressure', 'wind_speed',
            'hour', 'day_of_week', 'month', 'is_weekend', 'season',
            'pm_ratio', 'pollution_score', 'temp_humidity_index'
        ]
        
        # V√©rification que toutes les colonnes existent
        available_cols = [col for col in feature_cols if col in df.columns]
        if not available_cols:
            print("‚ùå Aucune feature disponible pour l'entra√Ænement")
            return None, None, None, None
        
        # Pr√©paration des donn√©es
        X = df[available_cols].fillna(0)
        y = df['aqi'].fillna(0)
        
        # Suppression des valeurs aberrantes
        Q1 = y.quantile(0.25)
        Q3 = y.quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        
        mask = (y >= lower_bound) & (y <= upper_bound)
        X = X[mask]
        y = y[mask]
        
        # Conversion en types num√©riques
        X = X.astype(float)
        y = y.astype(float)
        
        print(f"üîß Features pr√©par√©es: {X.shape[1]} colonnes, {len(X)} √©chantillons")
        print(f"üìä Plage AQI: {y.min():.1f} - {y.max():.1f}")
        
        # Division train/test
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )
        
        # Normalisation des features
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)
        
        return X_train_scaled, X_test_scaled, y_train, y_test
    
    def train_models(self, X_train, X_test, y_train, y_test, model_type='auto'):
        """Entra√Æne plusieurs mod√®les et s√©lectionne le meilleur"""
        print(f"ü§ñ Entra√Ænement des mod√®les (type: {model_type})...")
        
        # D√©finition des mod√®les √† tester
        models_to_train = {}
        
        if model_type in ['auto', 'randomforest', 'all']:
            models_to_train['RandomForest'] = RandomForestRegressor(
                n_estimators=100,
                max_depth=10,
                random_state=42,
                n_jobs=-1
            )
        
        if model_type in ['auto', 'xgboost', 'all']:
            models_to_train['XGBoost'] = xgb.XGBRegressor(
                n_estimators=100,
                max_depth=6,
                learning_rate=0.1,
                random_state=42,
                n_jobs=-1,
                verbosity=0
            )
        
        best_model = None
        best_score = float('inf')
        best_model_name = ""
        
        # Entra√Ænement et √©valuation de chaque mod√®le
        for name, model in models_to_train.items():
            print(f"üîÑ Entra√Ænement de {name}...")
            
            try:
                # Entra√Ænement
                model.fit(X_train, y_train)
                
                # Pr√©dictions
                y_pred = model.predict(X_test)
                
                # M√©triques
                mae = mean_absolute_error(y_test, y_pred)
                mse = mean_squared_error(y_test, y_pred)
                rmse = np.sqrt(mse)
                r2 = r2_score(y_test, y_pred)
                
                # Validation crois√©e
                cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='neg_mean_absolute_error')
                cv_mae = -cv_scores.mean()
                
                print(f"üìä {name} - MAE: {mae:.2f}, RMSE: {rmse:.2f}, R¬≤: {r2:.3f}, CV-MAE: {cv_mae:.2f}")
                
                # Sauvegarde du mod√®le
                self.models[name] = {
                    'model': model,
                    'mae': mae,
                    'rmse': rmse,
                    'r2': r2,
                    'cv_mae': cv_mae
                }
                
                # S√©lection du meilleur mod√®le bas√© sur le MAE
                if mae < best_score:
                    best_score = mae
                    best_model = model
                    best_model_name = name
                    
            except Exception as e:
                print(f"‚ùå Erreur lors de l'entra√Ænement de {name}: {e}")
                continue
        
        if best_model is None:
            print("‚ùå Aucun mod√®le entra√Æn√© avec succ√®s")
            return None, ""
        
        print(f"üèÜ Meilleur mod√®le: {best_model_name} (MAE: {best_score:.2f})")
        
        # Importance des features pour le meilleur mod√®le
        if hasattr(best_model, 'feature_importances_'):
            feature_names = [f"feature_{i}" for i in range(X_train.shape[1])]
            self.feature_importance = dict(zip(feature_names, best_model.feature_importances_))
        
        return best_model, best_model_name
    
    def save_model_to_registry(self, model, model_name, metrics, mr):
        """Sauvegarde le mod√®le dans le model registry"""
        try:
            # Sauvegarde locale du mod√®le
            model_dir = "aqi_model"
            os.makedirs(model_dir, exist_ok=True)
            
            # Sauvegarde du mod√®le et du scaler
            joblib.dump(model, f"{model_dir}/model.pkl")
            joblib.dump(self.scaler, f"{model_dir}/scaler.pkl")
            
            print(f"‚úÖ Mod√®le sauvegard√© localement dans {model_dir}/")
            
            # Si Hopsworks est disponible, sauvegarder dans le registry
            if mr is not None:
                # M√©tadonn√©es du mod√®le
                model_schema = {
                    "input_schema": {
                        "features": [
                            "pm25", "pm10", "o3", "no2", "so2", "co",
                            "temp", "humidity", "pressure", "wind_speed",
                            "hour", "day_of_week", "month", "is_weekend", "season",
                            "pm_ratio", "pollution_score", "temp_humidity_index"
                        ]
                    },
                    "output_schema": {
                        "predictions": ["aqi_prediction"]
                    }
                }
                
                # Cr√©ation du mod√®le dans le registry
                aqi_model = mr.python.create_model(
                    name="aqi_predictor",
                    version=1,
                    description=f"Mod√®le de pr√©diction AQI - {model_name}",
                    metrics=metrics,
                    model_schema=model_schema,
                    input_example=[[50, 80, 30, 25, 10, 5, 20, 60, 1013, 5, 
                                  12, 1, 6, False, 2, 0.6, 45, 12]],
                    model_dir=model_dir
                )
                
                print(f"‚úÖ Mod√®le sauvegard√© dans Hopsworks: {aqi_model.name} v{aqi_model.version}")
            else:
                print("‚ö†Ô∏è Hopsworks non disponible, sauvegarde locale uniquement")
                
        except Exception as e:
            print(f"‚ùå Erreur lors de la sauvegarde: {e}")
            print("‚úÖ Mod√®le sauvegard√© localement malgr√© l'erreur Hopsworks")
    
    def generate_model_report(self, model_name, metrics):
        """G√©n√®re un rapport sur le mod√®le entra√Æn√©"""
        report = f"""
# ü§ñ Rapport d'entra√Ænement du mod√®le AQI

## Mod√®le s√©lectionn√©: {model_name}

## üìä M√©triques de performance:
- **MAE (Mean Absolute Error)**: {metrics['mae']:.2f}
- **RMSE (Root Mean Square Error)**: {metrics['rmse']:.2f}
- **R¬≤ Score**: {metrics['r2']:.3f}
- **CV-MAE (Cross-Validation MAE)**: {metrics['cv_mae']:.2f}

## üéØ Interpr√©tation:
- **MAE**: En moyenne, les pr√©dictions diff√®rent de {metrics['mae']:.2f} points d'AQI
- **RMSE**: Mesure les erreurs importantes, valeur de {metrics['rmse']:.2f}
- **R¬≤**: Le mod√®le explique {metrics['r2']*100:.1f}% de la variance des donn√©es
- **CV-MAE**: Performance stable en validation crois√©e: {metrics['cv_mae']:.2f}

## ‚úÖ Qualit√© du mod√®le:
"""
        
        # √âvaluation de la qualit√©
        if metrics['mae'] < 15:
            report += "üü¢ **EXCELLENT** - MAE tr√®s faible\n"
        elif metrics['mae'] < 25:
            report += "üü° **BON** - MAE acceptable\n"
        else:
            report += "üî¥ **√Ä AM√âLIORER** - MAE √©lev√©e\n"
            
        if metrics['r2'] > 0.8:
            report += "üü¢ **EXCELLENT** - R¬≤ tr√®s √©lev√©\n"
        elif metrics['r2'] > 0.6:
            report += "üü° **BON** - R¬≤ satisfaisant\n"
        else:
            report += "üî¥ **√Ä AM√âLIORER** - R¬≤ faible\n"
        
        report += f"\n## üìÖ Date d'entra√Ænement: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
        
        return report
    
    def run_training_pipeline(self, model_type='auto'):
        """Ex√©cute le pipeline d'entra√Ænement complet"""
        print("üöÄ D√©marrage du pipeline d'entra√Ænement AQI...")
        print(f"üìÖ Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"ü§ñ Type de mod√®le: {model_type}")
        
        # Connexion √† Hopsworks
        fs, mr = self.connect_to_hopsworks()
        
        # Chargement des donn√©es (avec fallback sur donn√©es simul√©es)
        df = self.load_training_data(fs)
        if df.empty:
            print("‚ùå Aucune donn√©e disponible pour l'entra√Ænement")
            return False
        
        # Pr√©paration des features
        X_train, X_test, y_train, y_test = self.prepare_features(df)
        if X_train is None:
            print("‚ùå Impossible de pr√©parer les features")
            return False
        
        # Entra√Ænement des mod√®les
        best_model, best_model_name = self.train_models(X_train, X_test, y_train, y_test, model_type)
        
        if best_model is None:
            print("‚ùå Aucun mod√®le entra√Æn√© avec succ√®s")
            return False
        
        # M√©triques du meilleur mod√®le
        best_metrics = self.models[best_model_name]
        
        # Sauvegarde dans le model registry
        self.save_model_to_registry(best_model, best_model_name, best_metrics, mr)
        
        # G√©n√©ration du rapport
        report = self.generate_model_report(best_model_name, best_metrics)
        print(report)
        
        # Sauvegarde du rapport
        with open('training_report.md', 'w') as f:
            f.write(report)
        
        print("‚úÖ Pipeline d'entra√Ænement termin√© avec succ√®s")
        return True

def main():
    """Fonction principale avec gestion des arguments"""
    parser = argparse.ArgumentParser(description='Pipeline d\'entra√Ænement AQI')
    parser.add_argument('--model-type', type=str, default='auto',
                        choices=['auto', 'xgboost', 'randomforest', 'all'],
                        help='Type de mod√®le √† entra√Æner')
    
    args = parser.parse_args()
    
    # Cr√©ation et ex√©cution du pipeline
    training_pipeline = AQITrainingPipeline()
    success = training_pipeline.run_training_pipeline(args.model_type)
    
    # Code de sortie pour CI/CD
    sys.exit(0 if success else 1)

if __name__ == "__main__":
    main()